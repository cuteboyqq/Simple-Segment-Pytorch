# -*- coding: utf-8 -*-
"""
Created on Fri Apr  7 23:50:31 2023

@author: User
"""

import torch.nn.functional as F
import torch
import torch.nn as nn
import torch.models as models

'''
the DeepLabV3 class I wrote is for semantic segmentation. 
The model uses a ResNet50 backbone network and an Atrous Spatial Pyramid Pooling (ASPP) module to extract features from the input image.
The ASPP module is followed by a decoder network that upsamples the features to generate the final segmentation output.

The ASPP module employs dilated convolutions to capture multi-scale information and aggregate features across different receptive field sizes. 
This helps the model to handle objects of different sizes in the input image.

The final segmentation output is generated by upsampling the features using transposed convolutions 
and concatenating them with the corresponding features from the backbone network. 
The concatenated features are then passed through another set of convolutional layers to generate the final segmentation map.

Overall, this architecture is designed to achieve high accuracy in semantic segmentation tasks, 
particularly for tasks that involve segmenting objects of different sizes and shapes.
'''
class ConvBNReLU(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1):
        super(ConvBNReLU, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=False)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        
    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.relu(x)
        return x

class ASPP(nn.Module):
    def __init__(self, in_channels, out_channels, output_stride):
        super(ASPP, self).__init__()
        if output_stride == 16:
            dilations = [1, 6, 12, 18]
        elif output_stride == 8:
            dilations = [1, 12, 24, 36]
        else:
            raise NotImplementedError
        
        self.conv1 = ConvBNReLU(in_channels, out_channels, kernel_size=1)
        self.conv2 = ConvBNReLU(in_channels, out_channels, kernel_size=3, stride=1, padding=dilations[0], dilation=dilations[0])
        self.conv3 = ConvBNReLU(in_channels, out_channels, kernel_size=3, stride=1, padding=dilations[1], dilation=dilations[1])
        self.conv4 = ConvBNReLU(in_channels, out_channels, kernel_size=3, stride=1, padding=dilations[2], dilation=dilations[2])
        self.conv5 = ConvBNReLU(in_channels, out_channels, kernel_size=3, stride=1, padding=dilations[3], dilation=dilations[3])
        
        self.conv_bn_relu = nn.Sequential(
            nn.Conv2d(out_channels*5, out_channels, kernel_size=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        x1 = self.conv1(x)
        x2 = self.conv2(x)
        x3 = self.conv3(x)
        x4 = self.conv4(x)
        x5 = self.conv5(x)
        
        # Upsample the spatial size of the feature maps
        x2 = F.interpolate(x2, size=x1.shape[2:], mode='bilinear', align_corners=True)
        x3 = F.interpolate(x3, size=x1.shape[2:], mode='bilinear', align_corners=True)
        x4 = F.interpolate(x4, size=x1.shape[2:], mode='bilinear', align_corners=True)
        x5 = F.interpolate(x5, size=x1.shape[2:], mode='bilinear', align_corners=True)
        
        # Concatenate the feature maps along the channel dimension
        out = torch.cat([x1, x2, x3, x4, x5], dim=1)
        out = self.conv_bn_relu(out)
        
        return out

class DeepLabV3(nn.Module):
    def __init__(self, num_classes=21, output_stride=16):
        super(DeepLabV3, self).__init__()
        self.output_stride = output_stride
        
        # Define the backbone network
        self.backbone = models.resnet50(pretrained=True)
        
        # Remove the classification head
        del self.backbone.avgpool
        del self.backbone.fc
        
        # Modify the stride of the last convolutional block
        if output_stride == 8:
            self.backbone.layer4[0].conv2.stride = (1, 1)
            self.backbone.layer4[0].downsample[0].stride = (1, 1)
        
        # Define the ASPP module
        self.aspp = ASPP(in_channels=2048, output_stride=output_stride)
        
        # Define the decoder module
        self.decoder = nn.Sequential(
            ConvBNReLU(256, 48, kernel_size=1),
            nn.ConvTranspose2d(48, 48, kernel_size=4, stride=2, padding=1, output_padding=0, bias=False),
            nn.BatchNorm2d(48),
            nn.ReLU(inplace=True),
            ConvBNReLU(48, num_classes, kernel_size=1)
        )
        
    def forward(self, x):
        # Forward pass through the backbone network
        x = self.backbone.conv1(x)
        x = self.backbone.bn1(x)
        x = self.backbone.relu(x)
        x = self.backbone.maxpool(x)

        x = self.backbone.layer1(x)
        x = self.backbone.layer2(x)
        x = self.backbone.layer3(x)
        x = self.backbone.layer4(x)

        # Forward pass through the ASPP module
        x = self.aspp(x)

        # Forward pass through the decoder module
        x = self.decoder(x)

        # Upsample the output to the original size
        x = F.interpolate(x, size=input_size, mode='bilinear', align_corners=True)
        
        return x

